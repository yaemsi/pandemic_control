{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c792e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import gym\n",
    "import math\n",
    "import datetime\n",
    "import json\n",
    "\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_checker import check_env \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.legend import Legend\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib import colors\n",
    "\n",
    "\n",
    "from lib.train import train_standard\n",
    "from lib.plots import dynamics_cmap, comparison_cmap, set_plot_env, plot_model, plot_variance, plot_variance_comparison, plot_debug\n",
    "from lib.pandemic_model_tests import SEIVHRD_Env  \n",
    "from lib.data_structures import build_model_data, build_variance_struct, update_variance_struct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed0780f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTH = {\n",
    "    1: 'Jan',\n",
    "    2: 'Feb',\n",
    "    3: 'Mar',\n",
    "    4: 'Apr',\n",
    "    5: 'May',\n",
    "    6: 'Jun',\n",
    "    7: 'Jul',\n",
    "    8: 'Aug',\n",
    "    9: 'Sep',\n",
    "    10: 'Oct',\n",
    "    11: 'Nov',\n",
    "    12: 'Dec',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ade892b",
   "metadata": {},
   "source": [
    "Some functions to quickly preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "621265f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_month(date):\n",
    "    [y, m] =  date.split('-')[:2]\n",
    "    return f\"{MONTH[int(m)]} {y[2:]}\"\n",
    "\n",
    "\n",
    "# Routines to calculate the number of days between two dates. Useful for data preprocessing\n",
    "def convert_str_date_to_ints(date1, date2):\n",
    "    # Date is formatted as \"yyyy-mm-dd\"\n",
    "    [y1, m1, d1] = [int(elem) for elem in date1.split('-')]\n",
    "    [y2, m2, d2] = [int(elem) for elem in date2.split('-')]\n",
    "    if y1 > y2:\n",
    "        return  (y2, m2, d2), (y1, m1, d1)\n",
    "    elif y1 < y2:\n",
    "        return  (y1, m1, d1), (y2, m2, d2)\n",
    "    \n",
    "    if m1 > m2:\n",
    "        return  (y2, m2, d2), (y1, m1, d1)\n",
    "    elif m1 < m2:\n",
    "        return  (y1, m1, d1), (y2, m2, d2)\n",
    "    \n",
    "    if d1 > d2:\n",
    "        return  (y2, m2, d2), (y1, m1, d1)\n",
    "    \n",
    "    return  (y1, m1, d1), (y2, m2, d2)\n",
    "    \n",
    "def is_leap(year):\n",
    "    if (year % 4 == 0):\n",
    "        if (year % 100 != 0):\n",
    "            return True\n",
    "        else:\n",
    "            return (year % 400 == 0)\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_number_of_days(y, m):\n",
    "    if m in {1,3,5,7,8,10,12}:\n",
    "        return 31\n",
    "    elif m in {4,6,9,11}:\n",
    "        return 30\n",
    "    else:\n",
    "        return 29 if  is_leap(y) else 28\n",
    "\n",
    "def daysBetweenDates(y1, m1, d1, y2, m2, d2) -> int:\n",
    "    # Assumes y2 >= y1\n",
    "    days = 0\n",
    "    # Years\n",
    "    for y in range(y1 + 1, y2):\n",
    "        for m in range(1, 13):\n",
    "            days += get_number_of_days(y, m)\n",
    "    # Months\n",
    "    if y1 < y2:\n",
    "        for m in range(m1 + 1, 13):\n",
    "            days += get_number_of_days(y1, m)\n",
    "\n",
    "        for m in range(1, m2):\n",
    "            days += get_number_of_days(y2, m)\n",
    "\n",
    "    else:\n",
    "        for m in range(m1 + 1, m2):\n",
    "            days += get_number_of_days(y1, m)\n",
    "    # Days\n",
    "    if y1 == y2 and m1 == m2:\n",
    "        days += d2 - d1\n",
    "    else:\n",
    "        days += get_number_of_days(y1, m1) - d1  + d2\n",
    "    return days\n",
    "\n",
    "# Function used to keep selected periods\n",
    "def cut_off_dates(df, countries_dic):\n",
    "    new_df = df.copy(deep=True)\n",
    "    for country, (location_name, _, [start, end]) in countries_dic.items():\n",
    "        #print(f\"Length of {country} before drop == {len(new_df.loc[new_df['location']==country])}\")\n",
    "        index = new_df.loc[(new_df['location'] == location_name) & ((new_df['date'] < start) | (new_df['date'] > end))].index\n",
    "        new_df = new_df.drop(index , inplace=False)\n",
    "        #print(f\"Length of {country} after drop == {len(new_df.loc[new_df['location']==country])}\")\n",
    "    return new_df\n",
    "    \n",
    "\n",
    "def load_and_merge_dataframes(path_all, path_missing):\n",
    "    df_gcp_missing = pd.read_csv(path_missing)\n",
    "    df_gcp_missing = df_gcp_missing.drop(df_gcp_missing.columns[df_gcp_missing.columns.str.contains('unnamed',case = False)],axis = 1, inplace = False)\n",
    "    df_gcp_all = pd.read_csv(path_all)\n",
    "    df_gcp_all = df_gcp_all.drop(df_gcp_all.columns[df_gcp_all.columns.str.contains('unnamed',case = False)],axis = 1, inplace = False)\n",
    "    df_all = pd.concat([df_gcp_all, df_gcp_missing], axis=0)\n",
    "    return df_all\n",
    "\n",
    "\n",
    "\n",
    "def compute_initial_conditions(df, labels=\n",
    "                               ['cum_deceased',  \n",
    "                                'cum_confirmed',\n",
    "                                'current_hospitalized_patients',\n",
    "                                'cum_recovered',\n",
    "                                'cum_persons_vaccinated']):\n",
    "    mapping = {'cum_deceased':'D0',\n",
    "               'cum_confirmed':'I0',\n",
    "               'current_hospitalized_patients':'H0',\n",
    "               'cum_recovered':'R0',\n",
    "               'cum_persons_vaccinated':'V0'}\n",
    "    res = {'D0':0, 'I0':0, 'H0':0, 'R0':0, 'V0':0}\n",
    "    for lbl in labels:\n",
    "        sub_df = df[lbl]\n",
    "        if (len(sub_df) - sub_df.isna().sum()) < 2:\n",
    "            continue\n",
    "        sub_df = sub_df.tolist()\n",
    "        i = 0\n",
    "        first = sub_df[i]\n",
    "        while pd.isnull(first):\n",
    "            i += 1\n",
    "            first = sub_df[i]\n",
    "        \"\"\"\n",
    "        second = sub_df[i+1]\n",
    "        if not pd.isnull(second):\n",
    "            res[mapping[lbl]] = abs(second-first) # Abs not needed but we never know!\n",
    "        \"\"\"\n",
    "        res[mapping[lbl]] = first\n",
    "    return res\n",
    "\n",
    "\n",
    "def verify_df(df, N):\n",
    "    df = df.reset_index()  # make sure indexes pair with number of rows\n",
    "    for index, row in df.iterrows():\n",
    "        s = row['Deceased'] + row['Hospitalized'] + row['Infected_Asym'] + row['Infected_Sym'] + row['Vaccinated']  + row['Exposed'] + row['Recovered'] +  row['Susceptible']\n",
    "        if abs(s-N) > 1.:\n",
    "            raise ValueError(f\"Sum of variables ({s}) different from number of population ({N})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9539a0d",
   "metadata": {},
   "source": [
    "### Calculating vaccination rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fe6317a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "########### RESULTS FOR KEY new_persons_fully_vaccinated\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m########### RESULTS FOR KEY \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvacc_key\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m country \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnited Kingdom\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUnited States\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJapan\u001b[39m\u001b[38;5;124m'\u001b[39m]: \n\u001b[1;32m---> 13\u001b[0m     ([d1, d2], N) \u001b[38;5;241m=\u001b[39m countries_data[country]\n\u001b[0;32m     14\u001b[0m     df_view \u001b[38;5;241m=\u001b[39m df_gcp_missing[(df_gcp_missing[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m==\u001b[39mcountry) \u001b[38;5;241m&\u001b[39m ((df_gcp_missing[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m d1) \u001b[38;5;241m&\u001b[39m (df_gcp_missing[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m d2))]\n\u001b[0;32m     15\u001b[0m     cum_vacc \u001b[38;5;241m=\u001b[39m df_view[vacc_key]\u001b[38;5;241m.\u001b[39mcumsum()\u001b[38;5;241m.\u001b[39mtolist()\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "countries_data = {\n",
    "    'France':('france', 'France', ['2021-01-01','2021-12-31']),\n",
    "    'Italy':('italy' , 'Italy', ['2021-01-01','2021-12-31']),\n",
    "    'Malaysia':('malaysia' , 'Malaysia', ['2021-01-01','2021-12-31']),\n",
    "    'Japan':('japan', 'Japan', ['2021-01-01','2021-12-31']),\n",
    "    'United Kingdom':('united_kingdom' , 'United Kingdom', ['2021-01-01','2021-12-31']),\n",
    "    'United States':('united_states', 'United States', ['2021-01-01','2021-12-31'])\n",
    "}\n",
    "\n",
    "vacc_key = 'new_persons_fully_vaccinated'\n",
    "print(f\"########### RESULTS FOR KEY {vacc_key}\")\n",
    "for country in ['United Kingdom','United States','Japan']: \n",
    "    ([d1, d2], N) = countries_data[country]\n",
    "    df_view = df_gcp_missing[(df_gcp_missing['location']==country) & ((df_gcp_missing['date'] >= d1) & (df_gcp_missing['date'] <= d2))]\n",
    "    cum_vacc = df_view[vacc_key].cumsum().tolist()\n",
    "    rate = (cum_vacc[-1] - cum_vacc[0]) / len(df_view) / N\n",
    "    print(f\"Vaccination rate for the {country} is: {round(rate, 4)}\")\n",
    "for country in ['France','Italy','Malaysia']: \n",
    "    ([d1, d2], N) = countries_data[country]\n",
    "    df_view = df_gcp_all[(df_gcp_all['location']==country) & ((df_gcp_all['date'] >= d1) & (df_gcp_all['date'] <= d2))]\n",
    "    cum_vacc = df_view[vacc_key].cumsum().tolist()\n",
    "    rate = (cum_vacc[-1] - cum_vacc[0]) / len(df_view) / N\n",
    "    print(f\"Vaccination rate for the {country} is: {round(rate, 4)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b580f3e2",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90dfd0a",
   "metadata": {},
   "source": [
    "Below is the training code. We picked 6 countries for our simulations:\n",
    "\n",
    "1. 'France'\n",
    "2. 'Italy'\n",
    "3. 'Japan'\n",
    "4. 'Malaysia'\n",
    "5. 'United Kingdom'\n",
    "6. 'United States'\n",
    "\n",
    "We load countries' environments and train a PPO model on them. We save the model's weights at the end. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ad368f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################### Running training ##############################\n",
    "countries_data = {\n",
    "    'France':('france_new', 'France', ['2021-01-01','2021-12-31']),\n",
    "    'Italy':('italy' , 'Italy', ['2021-01-01','2021-12-31']),\n",
    "    'Malaysia':('malaysia' , 'Malaysia', ['2021-01-01','2021-12-31']),\n",
    "    'Japan':('japan', 'Japan', ['2021-01-01','2021-12-31']),\n",
    "    'United Kingdom':('united_kingdom' , 'United Kingdom', ['2021-01-01','2021-12-31']),\n",
    "    'United States':('united_states', 'United States', ['2021-01-01','2021-12-31'])\n",
    "}\n",
    "\n",
    "\n",
    "countries_data = {\n",
    "    #'France':('france_new', 'France', ['2021-01-01','2021-12-31']),\n",
    "    #'France':('france', 'France',  ['2021-01-01','20210-12-31']),\n",
    "    #'France_Health_Reward':('france_health_reward', 'France',  ['2021-01-01','20210-12-31']),\n",
    "    #'France_Health_Reward_Hosp_Weight':('france_health_reward_hosp_weight', 'France',  ['2021-01-01','20210-12-31']),\n",
    "    #'France_Health_Reward_Hosp_Weight_Max':('france_health_reward_hosp_weight_max', 'France', ['2021-01-01','20210-12-31']),\n",
    "    #'France_Health_Reward_Max':('france_health_reward_max', 'France',  ['2021-01-01','20210-12-31']),\n",
    "    #'France_Hosp_Dec_Health_Weights_Max':('france_hosp_dec_health_weights_max', 'France',  ['2021-01-01','20210-12-31']),\n",
    "    #'France_Hosp_Dec_Weights':('france_hosp_dec_weights', 'France',  ['2021-01-01','20210-12-31']),\n",
    "    #'France_Hosp_Dec_Weights_Max':('france_hosp_dec_weights_max', 'France',  ['2021-01-01','20210-12-31']),\n",
    "    #'France_Init_Cond':('france_init_cond', 'France',  ['2021-01-01','20210-12-31']),\n",
    "    #'France_Init_Cond_Reward_Hosp_Weight_Max':('france_init_cond_reward_hosp_weight_max', 'France',  ['2021-01-01','20210-12-31']),\n",
    "    #'France_Init_Cond_Hosp_Dec_Health_Weights_Max':('france_init_cond_hosp_dec_health_weights_max', 'France',  ['2021-01-01','20210-12-31']),\n",
    "}\n",
    "\n",
    "countries_data = {\n",
    "    'Paris':('paris', 'Paris', ['2020-03-18', '2021-03-18']),\n",
    "    #'Paris_Health_Reward_Hosp_Weight_Max':('paris_health_reward_hosp_weight_max', 'Paris', ['2020-03-18', '2021-03-18']),\n",
    "    #'Paris_Health_Reward_Max':('paris_health_reward_max', 'Paris', ['2020-03-18', '2021-03-18']),\n",
    "    #'Paris_Hosp_Dec_Health_Weights_Max':('paris_hosp_dec_health_weights_max', 'Paris', ['2020-03-18', '2021-03-18']),\n",
    "    #'Paris_Init_Cond_Hosp_Dec_Health_Weights_Max':('paris_init_cond_hosp_dec_health_weights_max', 'Paris', ['2020-03-18', '2021-03-18']),\n",
    "    #'IDF':('idf', 'Île-de-France',  ['2020-03-18', '2021-03-18']),\n",
    "    #'France_Health_Reward':('france_health_reward', 'France',  ['2021-01-01','20210-12-31']),\n",
    " }\n",
    "\n",
    "\n",
    "countries_data = {\n",
    "    'Singapore':('singapore', 'Singapore', ['2020-04-20', '2021-04-20']),\n",
    "    'Paris':('paris', 'Paris', ['2020-03-18', '2021-03-18']),\n",
    "    'New-York':('new-york', 'New-York', ['2020-04-11', '2021-04-11']),\n",
    "    'Tokyo':('tokyo', 'Tokyo', ['2020-05-08', '2021-05-08']),\n",
    " }\n",
    "\n",
    "\"\"\"\n",
    "Effective range for singapore city: ['2020-04-20', '2021-08-04']\n",
    "Effective range for paris city: ['2020-03-18', '2023-06-30']\n",
    "Effective range for new-york city: ['2020-04-11', '2023-03-23']\n",
    "Effective range for tokyo city: ['2020-05-08', '2023-05-07']\n",
    "\"\"\"\n",
    "\n",
    "for country, (f_name, location_key, _) in countries_data.items():\n",
    "    print(f\"############# Loading configuration file '{f_name}.json'\")\n",
    "    cfg_file = f_name + '.json'\n",
    "    with open(os.path.join(f'./config',f'{cfg_file}'), 'r') as ftp:\n",
    "        cfg = json.load(ftp)\n",
    "    \n",
    "    ### Pandemic Environnement \n",
    "    params = cfg['spec-params']\n",
    "    params_reg = cfg['env-params']\n",
    "    print(f\"############# Creating SEIVHRD environment\")\n",
    "    env = SEIVHRD_Env(params = params, **params_reg)\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    if 'init-conds' in cfg:\n",
    "        print(f\"############# Updating SEIVHRD environment with initial conditions\")\n",
    "        params_cond = cfg['init-conds']\n",
    "        env.update_initial_conditions(V0=params_cond['V0'], \n",
    "                                  E0=params_cond['E0'], \n",
    "                                  I_a0=params_cond['I_a0'], \n",
    "                                  I_s0=params_cond['I_s0'], \n",
    "                                  H0=params_cond['H0'], \n",
    "                                  R0=params_cond['R0'], \n",
    "                                  D0=params_cond['D0'])\n",
    "    \"\"\"\n",
    "    check_env(env)\n",
    "    \n",
    "    print(f\"############# Creating RL model\")\n",
    "    agent_type = \"PPO\"\n",
    "    save_dir = f\"./outputs/simulations/{agent_type}/{f_name}\"\n",
    "    os.makedirs(save_dir, exist_ok=True)  \n",
    "    weights_dir = os.path.join(save_dir, \"weights\")\n",
    "    log_dir = os.path.join(save_dir, \"logs\")\n",
    "    \n",
    "    model_ppo = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)\n",
    "\n",
    "    TIMESTEPS, EPOCHS = 730, 200 # 2 years\n",
    "    env.max_steps = round(TIMESTEPS / env.days)\n",
    "    \n",
    "    print(f\"############# Training RL model for {TIMESTEPS} steps\")\n",
    "    for index in range(0, EPOCHS):\n",
    "        print(f\"##### Epoch number {index}\")\n",
    "        model_ppo.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"PPO_{f_name}\")\n",
    "        if index % 10 == 0:\n",
    "            model_ppo.save(f\"{weights_dir}_{index}_{TIMESTEPS}\")\n",
    "    print(f\"##### Saving final model at '{weights_dir}_{index+1}_{TIMESTEPS}'\")\n",
    "    model_ppo.save(f\"{weights_dir}_{index+1}_{TIMESTEPS}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6eebf4",
   "metadata": {},
   "source": [
    "### Running predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af13ff7b",
   "metadata": {},
   "source": [
    "We load the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3bde22bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>cum_confirmed</th>\n",
       "      <th>cum_deceased</th>\n",
       "      <th>cum_recovered</th>\n",
       "      <th>cum_persons_vaccinated</th>\n",
       "      <th>current_hospitalized_patients</th>\n",
       "      <th>population</th>\n",
       "      <th>location</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-20</td>\n",
       "      <td>8014.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>801.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1364.0</td>\n",
       "      <td>5638676</td>\n",
       "      <td>singapore</td>\n",
       "      <td>Apr 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-04-21</td>\n",
       "      <td>9125.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>839.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>5638676</td>\n",
       "      <td>singapore</td>\n",
       "      <td>Apr 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-04-22</td>\n",
       "      <td>10141.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>896.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1571.0</td>\n",
       "      <td>5638676</td>\n",
       "      <td>singapore</td>\n",
       "      <td>Apr 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-04-23</td>\n",
       "      <td>11178.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1342.0</td>\n",
       "      <td>5638676</td>\n",
       "      <td>singapore</td>\n",
       "      <td>Apr 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-04-24</td>\n",
       "      <td>12075.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>956.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1205.0</td>\n",
       "      <td>5638676</td>\n",
       "      <td>singapore</td>\n",
       "      <td>Apr 20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3151</th>\n",
       "      <td>2023-05-03</td>\n",
       "      <td>4382724.0</td>\n",
       "      <td>8111.0</td>\n",
       "      <td>3093983.0</td>\n",
       "      <td>15748511.0</td>\n",
       "      <td>47585.0</td>\n",
       "      <td>13942856</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>May 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3152</th>\n",
       "      <td>2023-05-04</td>\n",
       "      <td>4383630.0</td>\n",
       "      <td>8114.0</td>\n",
       "      <td>3093983.0</td>\n",
       "      <td>15748511.0</td>\n",
       "      <td>47592.0</td>\n",
       "      <td>13942856</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>May 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3153</th>\n",
       "      <td>2023-05-05</td>\n",
       "      <td>4384692.0</td>\n",
       "      <td>8117.0</td>\n",
       "      <td>3093983.0</td>\n",
       "      <td>15748511.0</td>\n",
       "      <td>47599.0</td>\n",
       "      <td>13942856</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>May 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3154</th>\n",
       "      <td>2023-05-06</td>\n",
       "      <td>4387037.0</td>\n",
       "      <td>8120.0</td>\n",
       "      <td>3093983.0</td>\n",
       "      <td>15748511.0</td>\n",
       "      <td>47562.0</td>\n",
       "      <td>13942856</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>May 23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3155</th>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>4388368.0</td>\n",
       "      <td>8124.0</td>\n",
       "      <td>3093983.0</td>\n",
       "      <td>15748511.0</td>\n",
       "      <td>47511.0</td>\n",
       "      <td>13942856</td>\n",
       "      <td>tokyo</td>\n",
       "      <td>May 23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3156 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  cum_confirmed  cum_deceased  cum_recovered  \\\n",
       "0     2020-04-20         8014.0          11.0          801.0   \n",
       "1     2020-04-21         9125.0          11.0          839.0   \n",
       "2     2020-04-22        10141.0          12.0          896.0   \n",
       "3     2020-04-23        11178.0          12.0          924.0   \n",
       "4     2020-04-24        12075.0          12.0          956.0   \n",
       "...          ...            ...           ...            ...   \n",
       "3151  2023-05-03      4382724.0        8111.0      3093983.0   \n",
       "3152  2023-05-04      4383630.0        8114.0      3093983.0   \n",
       "3153  2023-05-05      4384692.0        8117.0      3093983.0   \n",
       "3154  2023-05-06      4387037.0        8120.0      3093983.0   \n",
       "3155  2023-05-07      4388368.0        8124.0      3093983.0   \n",
       "\n",
       "      cum_persons_vaccinated  current_hospitalized_patients  population  \\\n",
       "0                        2.0                         1364.0     5638676   \n",
       "1                        2.0                         1381.0     5638676   \n",
       "2                        2.0                         1571.0     5638676   \n",
       "3                        2.0                         1342.0     5638676   \n",
       "4                        2.0                         1205.0     5638676   \n",
       "...                      ...                            ...         ...   \n",
       "3151              15748511.0                        47585.0    13942856   \n",
       "3152              15748511.0                        47592.0    13942856   \n",
       "3153              15748511.0                        47599.0    13942856   \n",
       "3154              15748511.0                        47562.0    13942856   \n",
       "3155              15748511.0                        47511.0    13942856   \n",
       "\n",
       "       location   month  \n",
       "0     singapore  Apr 20  \n",
       "1     singapore  Apr 20  \n",
       "2     singapore  Apr 20  \n",
       "3     singapore  Apr 20  \n",
       "4     singapore  Apr 20  \n",
       "...         ...     ...  \n",
       "3151      tokyo  May 23  \n",
       "3152      tokyo  May 23  \n",
       "3153      tokyo  May 23  \n",
       "3154      tokyo  May 23  \n",
       "3155      tokyo  May 23  \n",
       "\n",
       "[3156 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = None\n",
    "countries_data = {\n",
    "    'Singapore':('singapore', 'Singapore', ['2020-04-20', '2021-04-20']),\n",
    "    'Paris':('paris', 'Paris', ['2020-03-18', '2021-03-18']),\n",
    "    'New-York':('new-york', 'New-York', ['2020-04-11', '2021-04-11']),\n",
    "    'Tokyo':('tokyo', 'Tokyo', ['2020-05-08', '2021-05-08']),\n",
    " }\n",
    "for city, (f_name, location_key, _) in countries_data.items():\n",
    "    df = pd.read_csv(os.path.join(f\"./data/cities/preprocessed\",f\"{city}.csv\"))\n",
    "    #print(f\"############# Number of rows for city {f_name} == {len(df)}\")\n",
    "    #for col in df.columns:\n",
    "    #    print(f\"===>>> Number of NaN for column '{col}' = {df[col].isna().sum()}\")\n",
    "    #print(f\"columns for city {f_name} are : {df.columns}\")\n",
    "    if df_all is None:\n",
    "        df_all = df\n",
    "    else:\n",
    "        df_all = pd.concat([df_all, df], ignore_index=True)\n",
    "df_truncated = df_all.drop(df_all.columns[df_all.columns.str.contains('Unnamed',case = False)], axis = 1, inplace = False)\n",
    "#df_truncated = cut_off_dates(df_truncated, countries_data)\n",
    "df_truncated = df_truncated.interpolate(method='linear', limit_direction='both', axis=0)\n",
    "df_truncated['month'] = df_truncated['date'].apply(extract_month)\n",
    "df_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d313e590",
   "metadata": {},
   "source": [
    "We now load both the model and environment and run predictions. We save them at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8595f4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Loading configuration for country Singapore\n",
      "############# Creating SEIVHRD environment\n",
      "############# Loading trained RL model\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "############# Running inference\n",
      "############# Saving the results...\n",
      "############# Loading configuration for country Paris\n",
      "############# Creating SEIVHRD environment\n",
      "############# Loading trained RL model\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "############# Running inference\n",
      "############# Saving the results...\n",
      "############# Loading configuration for country New-York\n",
      "############# Creating SEIVHRD environment\n",
      "############# Loading trained RL model\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "############# Running inference\n",
      "############# Saving the results...\n",
      "############# Loading configuration for country Tokyo\n",
      "############# Creating SEIVHRD environment\n",
      "############# Loading trained RL model\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "############# Running inference\n",
      "############# Saving the results...\n"
     ]
    }
   ],
   "source": [
    "#################### Running predictions ##############################\n",
    "countries_data = {\n",
    "    'Singapore':('singapore', 'Singapore', ['2020-04-20', '2021-04-20']),\n",
    "    'Paris':('paris', 'Paris', ['2020-03-18', '2021-03-18']),\n",
    "    'New-York':('new-york', 'New-York', ['2020-04-11', '2021-04-11']),\n",
    "    'Tokyo':('tokyo', 'Tokyo', ['2020-05-08', '2021-05-08']),\n",
    " }\n",
    "\n",
    "TIMESTEPS, EPOCHS = 730, 200 # 3 years\n",
    "WINDOW = 1095\n",
    "\n",
    "for country, (f_name, location_key, [d1, d2]) in countries_data.items():\n",
    "    country = country.split('_')[0]\n",
    "    print(f\"############# Loading configuration for country {country}\")\n",
    "    cfg_file = f_name + '.json'\n",
    "    with open(os.path.join(f'./config',f'{cfg_file}'), 'r') as ftp:\n",
    "        cfg = json.load(ftp)\n",
    "    \n",
    "    ### Pandemic Environnement \n",
    "    params = cfg['spec-params']\n",
    "    params_reg = cfg['env-params']\n",
    "    print(f\"############# Creating SEIVHRD environment\")\n",
    "    env = SEIVHRD_Env(params = params, **params_reg)\n",
    "    env.max_steps = round(WINDOW / env.days)\n",
    "    check_env(env)\n",
    "    \n",
    "    \n",
    "    ### Model \n",
    "    print(f\"############# Loading trained RL model\")\n",
    "    agent_type = \"PPO\"\n",
    "    save_dir = f\"./outputs/simulations/{agent_type}/{f_name}\"\n",
    "    weights_dir = os.path.join(save_dir, \"weights\")\n",
    "    log_dir = os.path.join(save_dir, \"logs\")\n",
    "    model_ppo = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)\n",
    "    model_ppo.load(f\"{weights_dir}_{EPOCHS}_{TIMESTEPS}\")\n",
    "\n",
    "\n",
    "    ### Inference\n",
    "    print(f\"############# Running inference\")\n",
    "    data_variance, rounds = build_variance_struct(), 1000\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    cum_confirmed, \n",
    "    cum_deceased,\n",
    "    cum_recovered, \n",
    "    vaccines, \n",
    "    cum_persons_vaccinated, \n",
    "    current_hospitalized_patients\n",
    "    \"\"\"\n",
    "   \n",
    "    df = df_truncated.loc[(df_truncated['location']==f_name)]\n",
    "    \"\"\"\n",
    "    init_conds = compute_initial_conditions(\n",
    "        df, \n",
    "        labels = ['cum_deceased',\n",
    "                  'cum_confirmed',\n",
    "                  'current_hospitalized_patients',\n",
    "                  'cum_recovered',\n",
    "                  'cum_persons_vaccinated']\n",
    "    )\n",
    "    print(f\"Initial conditions == {init_conds}\")\n",
    "    env.update_initial_conditions(V0=init_conds['V0'], \n",
    "                                  E0=0, \n",
    "                                  I_a0=0, \n",
    "                                  I_s0=init_conds['I0'], \n",
    "                                  H0=init_conds['H0'], \n",
    "                                  R0=init_conds['R0'], \n",
    "                                  D0=init_conds['D0'])\n",
    "    \"\"\"\n",
    "\n",
    "    for i in range(rounds):\n",
    "        run_data = train_standard(env, model=model_ppo, T_max=TIMESTEPS, mode=\"Predict\")\n",
    "        data_variance = update_variance_struct(data_variance, run_data)\n",
    "\n",
    "\n",
    "    ### Saving the structure\n",
    "    print(f\"############# Saving the results...\")\n",
    "    dataframe_path = f\"./outputs/simulations/{agent_type}/results\"\n",
    "    os.makedirs(dataframe_path, exist_ok=True)\n",
    "    if 'Infected_cumul' in data_variance:\n",
    "        del data_variance['Infected_cumul'] # We don't need this one\n",
    "    df = pd.DataFrame.from_dict(data_variance)\n",
    "    df = df.drop(df.columns[df.columns.str.contains('Unnamed',case = False)], axis = 1, inplace = False)\n",
    "    df.to_csv(f\"{os.path.join(dataframe_path,f_name)}_results.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d39e6a",
   "metadata": {},
   "source": [
    "### Plotting curves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b04aac",
   "metadata": {},
   "source": [
    "We now plot the curves together (real vs simulated). We compare cumulated deaths and hospitalized patients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3844923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############# Loading the dataframe from './outputs/simulations/PPO/results/singapore_results.csv'...\n",
      "############# Loading configuration for country singapore\n",
      "############# Creating SEIVHRD environment\n",
      "############# Plotting simulations\n",
      "## Comparison with real data\n",
      "## Everything together\n",
      "### Variances\n",
      "############# Loading the dataframe from './outputs/simulations/PPO/results/paris_results.csv'...\n",
      "############# Loading configuration for country paris\n",
      "############# Creating SEIVHRD environment\n",
      "############# Plotting simulations\n",
      "## Comparison with real data\n",
      "## Everything together\n",
      "### Variances\n",
      "############# Loading the dataframe from './outputs/simulations/PPO/results/new-york_results.csv'...\n",
      "############# Loading configuration for country new-york\n",
      "############# Creating SEIVHRD environment\n",
      "############# Plotting simulations\n",
      "## Comparison with real data\n",
      "## Everything together\n",
      "### Variances\n",
      "############# Loading the dataframe from './outputs/simulations/PPO/results/tokyo_results.csv'...\n",
      "############# Loading configuration for country tokyo\n",
      "############# Creating SEIVHRD environment\n",
      "############# Plotting simulations\n",
      "## Comparison with real data\n",
      "## Everything together\n",
      "### Variances\n"
     ]
    }
   ],
   "source": [
    "agent_type = \"PPO\"\n",
    "\n",
    "comparison_cmap = {\n",
    "    'Hospitalized':'xkcd:blue',\n",
    "    'Hospitalized_ref':'xkcd:red',\n",
    "    'Recovered':'xkcd:blue',\n",
    "    'Recovered_ref': 'xkcd:red',\n",
    "    'Deceased':'xkcd:blue',\n",
    "    'Deceased_ref':'xkcd:red',\n",
    "    'Infected':'xkcd:blue',\n",
    "    'Infected_cum':'xkcd:blue',\n",
    "    'Infected_ref': 'xkcd:red',\n",
    "}\n",
    "\n",
    "def plot_variance(env, data, filepath, xlim=366):\n",
    "\n",
    "    _, axis = plt.subplots(ncols=1, nrows=1, figsize=(10, 8), facecolor=\"#ffffff\")\n",
    "    #figure.suptitle('Variations', fontsize=18)\n",
    "    sns.lineplot(x='Days', y='Economy', label='Economy',  color=dynamics_cmap['Economy'], data=data, ax=axis, linewidth=2.5).set(ylabel=None, xlabel=\"Days\")\n",
    "    axis.legend(loc=\"best\")\n",
    "    plt.xlim(left=0, right=xlim)\n",
    "    plt.savefig(filepath+f\"_eco.pdf\", pad_inches=0, bbox_inches='tight', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "    _, axis = plt.subplots(ncols=1, nrows=1, figsize=(10, 8), facecolor=\"#ffffff\")\n",
    "    sns.lineplot(x='Days', y='Actions', label='Actions', color=dynamics_cmap['Actions'], data=data, ax=axis, linewidth=2.5).set(ylabel=None, xlabel=\"Days\")\n",
    "    axis.legend(loc=\"best\")\n",
    "    plt.xlim(left=0, right=xlim)\n",
    "    \n",
    "    plt.savefig(filepath+f\"_actions.pdf\", pad_inches=0, bbox_inches='tight', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "    _, axis = plt.subplots(ncols=1, nrows=1, figsize=(10, 8), facecolor=\"#ffffff\")\n",
    "    sns.lineplot(x='Days', y='Infected', data=data,  color=dynamics_cmap['Infected'], ax=axis, label=\"Infected\", linewidth=2.5).set(xlabel=\"Days\", ylabel=None)\n",
    "    axis.legend(loc=\"best\")\n",
    "    plt.xlim(left=0, right=xlim)\n",
    "    \n",
    "    plt.savefig(filepath+f\"_infections.pdf\", pad_inches=0, bbox_inches='tight', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "    _, axis = plt.subplots(ncols=1, nrows=1, figsize=(10, 8), facecolor=\"#ffffff\")\n",
    "    sns.lineplot(x='Days', y='Deceased', data=data,  color=dynamics_cmap['Deceased'], ax=axis, label='Deceased', linewidth=2.5).set(xlabel=\"Days\", ylabel=None)\n",
    "    axis.legend(loc=\"best\")\n",
    "    plt.xlim(left=0, right=xlim)\n",
    "    \n",
    "    plt.savefig(filepath+f\"_deceased.pdf\", pad_inches=0, bbox_inches='tight', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "    _, axis = plt.subplots(ncols=1, nrows=1, figsize=(10,8), facecolor=\"#ffffff\")\n",
    "    p = sns.lineplot(x='Days', y='Hospitalized', data=data, color=dynamics_cmap['Hospitalized'], ax=axis, label='Hospitalized', linewidth=2.5)\n",
    "    p.set(xlabel=\"Days\", ylabel=None)\n",
    "    p.axhline(env.hospital_capacity, color=\"r\", linestyle='--',label=r'$C_{h}$', linewidth=2.5)\n",
    "    p.legend(loc=\"best\")\n",
    "    plt.xlim(left=0, right=xlim)\n",
    "    \n",
    "    plt.savefig(filepath+f\"_hospitalized.pdf\", pad_inches=0, bbox_inches='tight', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "    ### All dynamics\n",
    "    _, axis = plt.subplots(ncols=1, nrows=1, figsize=(10, 8), facecolor=\"#ffffff\")\n",
    "    sns.lineplot(x='Days', y='Infected', data=data,  color=dynamics_cmap['Infected'], ax=axis, label=\"Infected\", linewidth=2.5).set(xlabel=\"Days\", ylabel=None)\n",
    "    sns.lineplot(x='Days', y='Deceased', data=data,  color=dynamics_cmap['Deceased'], ax=axis, label='Deceased', linewidth=2.5).set(xlabel=\"Days\", ylabel=None)\n",
    "    sns.lineplot(x='Days', y='Hospitalized', data=data, color=dynamics_cmap['Hospitalized'], ax=axis, label='Hospitalized', linewidth=2.5).set(xlabel=\"Days\", ylabel=None)\n",
    "    axis.axhline(env.hospital_capacity, color=\"r\", linestyle='--',label=r'$C_{h}$', linewidth=2.5)\n",
    "    axis.legend(loc=\"best\")\n",
    "    plt.xlim(left=0, right=xlim)\n",
    "    \n",
    "    plt.savefig(filepath+f\"_dynamics.pdf\", pad_inches=0, bbox_inches='tight', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "def plot_debug(data, hosp_cap = None, file_path='./out.pdf', xlim = None, \n",
    "               labels=[\n",
    "                'Hospitalized', \n",
    "                'Deceased', \n",
    "                'Recovered', \n",
    "                #'Infected_cum',\n",
    "                'Infected',\n",
    "                'Susceptible',\n",
    "                'Vaccinated',\n",
    "                'Exposed']):\n",
    "    ### All labels\n",
    "    _, axis = plt.subplots(ncols=1, nrows=1, figsize=(10, 8), facecolor=\"#ffffff\")\n",
    "    for label in labels:\n",
    "        # Results of agent's management\n",
    "        sns.lineplot(x='Days', y=label, data=data,  color=dynamics_cmap[label], ax=axis, label=label, linewidth=2.5).set(xlabel=\"Days\", ylabel=None)\n",
    "    # Actual numbers\n",
    "    axis.legend(loc=\"best\")\n",
    "    if hosp_cap:\n",
    "        axis.axhline(hosp_cap, color=\"r\", linestyle='--',label=r'$C_{h}$', linewidth=2.5)\n",
    "    if xlim is not None:\n",
    "        plt.xlim(left=0, right=xlim)\n",
    "    else:\n",
    "        plt.xlim(left=0)\n",
    "    plt.savefig(f\"{file_path}.pdf\", pad_inches=0, bbox_inches='tight', transparent=True)\n",
    "    plt.close()\n",
    "\n",
    "def plot_variance_comparison(data, reference, hosp_cap = None, file_path='./out.pdf', labels=['Hospitalized', 'Deceased']):\n",
    "    label_map = {\n",
    "        'Hospitalized': 'current_hospitalized_patients',\n",
    "        'Deceased': 'cum_deceased',\n",
    "    }\n",
    "\n",
    "    ### All labels\n",
    "    for label in labels:\n",
    "        _, axis = plt.subplots(ncols=1, nrows=1, figsize=(10, 8), facecolor=\"#ffffff\")\n",
    "        # Results of agent's management\n",
    "        sns.lineplot(\n",
    "            x='Days', y=label, data=data, color=comparison_cmap[label], ax=axis, label=\"Simulation\", \n",
    "            linewidth=2.5).set(xlabel=None, ylabel=label) #.set(xlabel=\"Days\", ylabel=label)\n",
    "\n",
    "        # Actual numbers\n",
    "        sns.lineplot(\n",
    "            x='Days', y=label_map[label], data=reference,  color=comparison_cmap[f\"{label}_ref\"], ax=axis, \n",
    "            label=f\"Real data\", linewidth=1.8).set(xlabel=None, ylabel=label) #.set(xlabel=\"Days\", ylabel=None)\n",
    "\n",
    "        #axis.set_xticks(reference['Days'], minor=True, direction='in')\n",
    "        step, rot = 90, 60\n",
    "        plt.xticks(\n",
    "            list(range(0, len(reference), step)), \n",
    "            [reference['month'].iloc[i] for i in range(0, len(reference), step)],\n",
    "            minor=False,\n",
    "            rotation=rot)\n",
    "        if label == \"Hospitalized\":\n",
    "            if not hosp_cap:\n",
    "                raise ValueError(f\"Hospitals number 'hosp_cap' should be provided when plotting hospitalized counts.\")\n",
    "            axis.axhline(hosp_cap, color=\"grey\", linestyle='--',label=r'$C_{h}$', linewidth=2.5)\n",
    "        axis.set_yscale('log')\n",
    "        axis.legend(loc=\"best\")\n",
    "        plt.xlim(right=min(len(data), len(reference)) + 1)\n",
    "        plt.savefig(f\"{file_path}_{label}.pdf\", pad_inches=0, bbox_inches='tight', transparent=True)\n",
    "        plt.close()\n",
    "\n",
    "countries_data = {\n",
    "    'Singapore':('singapore', 'Singapore', ['2020-04-20', '2021-04-20']),\n",
    "    'Paris': ('paris', 'Paris', ['2020-03-18', '2021-03-18']),\n",
    "    'New-York':('new-york', 'New-York', ['2020-04-11', '2021-04-11']),\n",
    "    'Tokyo':('tokyo', 'Tokyo', ['2020-05-08', '2021-05-08']),\n",
    " }\n",
    "\n",
    "for key, (country, location_key, _) in countries_data.items():\n",
    "    dataframe_path = f\"./outputs/simulations/{agent_type}/results/{country}_results.csv\"\n",
    "    print(f\"############# Loading the dataframe from '{dataframe_path}'...\")\n",
    "    df_sim = pd.read_csv(f\"{dataframe_path}\")\n",
    "    df_sim = df_sim.groupby('Days', as_index=False).mean()\n",
    "    \n",
    "    print(f\"############# Loading configuration for country {country}\")\n",
    "    cfg_file = country + '.json'\n",
    "    with open(os.path.join(f'./config',f'{cfg_file}'), 'r') as ftp:\n",
    "        cfg = json.load(ftp)\n",
    "    \n",
    "    ### Pandemic Environnement \n",
    "    params = cfg['spec-params']\n",
    "    params_reg = cfg['env-params']\n",
    "    print(f\"############# Creating SEIVHRD environment\")\n",
    "    env = SEIVHRD_Env(params = params, **params_reg)\n",
    "    check_env(env)\n",
    "    \n",
    "    #print(f\"############# Verifying the saved predictions\")\n",
    "    #verify_df(df_sim, params_reg['N'])\n",
    "    \n",
    "    print(f\"############# Plotting simulations\")\n",
    "    df_ref = df_truncated.loc[df_truncated['location']==country]\n",
    "    #df_ref = add_cummulative_col(df_ref, 'new_deceased', 'new_deceased_cum')\n",
    "    #df_ref.insert(1, \"new_deceased_cum\", df_ref['new_deceased'].cumsum())\n",
    "    df_ref.insert(0, 'Days', range(1, 1 + len(df_ref)))\n",
    "    \n",
    "    dir_path = f\"./outputs/simulations/plots/{agent_type}\"\n",
    "    os.makedirs(dir_path, exist_ok=True)\n",
    "    print(f\"## Comparison with real data\")\n",
    "    plot_variance_comparison(df_sim, df_ref, cfg['env-params']['hosp_cap'], os.path.join(dir_path, f\"{country}\") , labels=['Hospitalized', 'Deceased'])    \n",
    "    print(f\"## Everything together\")\n",
    "    #df_sim.insert(0, \"Infected_cum\", df_sim['Infected_Asym'] + df_sim['Infected_Sym'])\n",
    "    #plot_debug(df_sim, cfg['env-params']['hosp_cap'], os.path.join(dir_path, f\"{country}_all\"), xlim=366)\n",
    "    plot_debug(df_sim, None, os.path.join(dir_path, f\"{country}_all\"), xlim=366)\n",
    "    print(f\"### Variances\")\n",
    "    plot_variance(env, df_sim, os.path.join(dir_path, f\"{country}_variances\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936dc925",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee18598",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1fd3af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sim.groupby('Days', as_index=False).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
