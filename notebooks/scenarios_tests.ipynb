{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2754af4e",
   "metadata": {},
   "source": [
    "# Tests des différents scénarios\n",
    "\n",
    "## Etape 1 : importer les modules nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4c792e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Importer les algorithmes RL #############\n",
    "from stable_baselines3 import PPO        # PPO\n",
    "from stable_baselines3 import DQN        # DQN \n",
    "from stable_baselines3 import A2C        # A2C \n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "######### Importer les fichier des modules implémentés ##########\n",
    "from lib.pandemic_model_tests import SEIVHRD_Env           # Environnement\n",
    "from lib.plots import plot_model, plot_variance            # Modules de visualisation\n",
    "from lib.train import train_standard, simulate_episodes    # Module d'execution de la simulation\n",
    "from lib.data_structures import build_model_data, build_variance_struct, update_variance_struct   #Structures de données\n",
    "\n",
    "############# Modules python complémentaires ###############\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142ad911",
   "metadata": {},
   "source": [
    "## Etape 2 : construction de l'environnement RL \n",
    "Nous importons les parametres et les arguments du modèle à partir des fichiers json externes que nous avons remplis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a987c7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Construire l'environnement #############\n",
    "with open('config/params.json', 'r') as f1:\n",
    "  params = json.load(f1)\n",
    "with open('config/env-setup-ville.json', 'r') as f2:\n",
    "  kwargs = json.load(f2)\n",
    "#intsance du ME\n",
    "env = SEIVHRD_Env(params = params, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214b9dce",
   "metadata": {},
   "source": [
    "## Cas de test 2 : Tester avec différents algorithmes d'entrainement\n",
    "Le but de ce test est de visualiser et comparer les stratégies des agents entrainés avec des algorithmes différents\n",
    "### 1 - Algorithme PPO :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d8d5e03",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############# Simuler X épisodes de l'épidémie avec la stratégie de l'agentPPO #############\n",
    "algo_name = \"PPO\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"Default\")\n",
    "models_dir = os.path.join(models_dir,f\"{algo_name}\")\n",
    "model = PPO.load(models_dir)                        # Charger l'agent RL\n",
    "num_episodes = 100                                  # Nombre d'épisodes simulés\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_2\")\n",
    "simulate_episodes(env, model, 1, results_dir, algo_name)\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0223324c",
   "metadata": {},
   "source": [
    "### 2 - Algorithme DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5158b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Simuler X épisodes de l'épidémie avec la stratégie de l'agentPPO #############\n",
    "algo_name = \"DQN\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"Default\")\n",
    "models_dir = os.path.join(models_dir,f\"{algo_name}\")\n",
    "model = DQN.load(models_dir)                        # Charger l'agent RL\n",
    "num_episodes = 100                                  # Nombre d'épisodes simulés\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_2\")\n",
    "simulate_episodes(env, model, 1, results_dir, algo_name)\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8804b8",
   "metadata": {},
   "source": [
    "### 3 - Algorithme DDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44087f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############# Simuler X épisodes de l'épidémie avec la stratégie de l'agentPPO #############\n",
    "algo_name = \"DDQN\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"Default\")\n",
    "models_dir = os.path.join(models_dir,f\"{algo_name}\")\n",
    "model = DQN.load(models_dir)                        # Charger l'agent RL\n",
    "num_episodes = 100                                  # Nombre d'épisodes simulés\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_2\")\n",
    "simulate_episodes(env, model, 1, results_dir, algo_name)\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e2d9f6",
   "metadata": {},
   "source": [
    "### 4 - Algorithme A2C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4decc4b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "############# Simuler X épisodes de l'épidémie avec la stratégie de l'agentPPO #############\n",
    "algo_name = \"A2C\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"Default\")\n",
    "models_dir = os.path.join(models_dir,f\"{algo_name}\")\n",
    "model = A2C.load(models_dir)                        # Charger l'agent RL\n",
    "num_episodes = 100                                  # Nombre d'épisodes simulés\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_2\")\n",
    "simulate_episodes(env, model, 1, results_dir, algo_name)\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ca3ead",
   "metadata": {},
   "source": [
    "## Cas de test 3 : Tester avec différents délais de prise de décision\n",
    "le but de ce test est de savoir si le délai de prise de décision impacte la stratégie de l'agent\n",
    "### 1 - Délai de 3 jours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30eaed56",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Tester la stratégie pour un délai de prise de décision de 3 jours#############\n",
    "with open('./config/env-setup-3days.json', 'r') as fp:\n",
    "  kwargs_3days = json.load(fp)\n",
    "\n",
    "env_3days = SEIVHRD_Env(params = params, **kwargs_3days)\n",
    "\n",
    "algo_name = \"PPO\"\n",
    "models_dir = os.path.join(\"./outputs/model\",\"3daysTest\")\n",
    "models_dir = os.path.join(models_dir,\"3days_rest\")\n",
    "model = PPO.load(models_dir)                        # Charger l'agent RL\n",
    "num_episodes = 100                                  # Nombre d'épisodes simulés\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_3\")\n",
    "simulate_episodes(env_3days, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf3f018",
   "metadata": {},
   "source": [
    "### 2 - Délai de 15 jours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d36fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Tester la stratégie pour un délai de prise de décision de 15 jours#############\n",
    "with open('./config/env-setup-15days.json', 'r') as fp:\n",
    "  kwargs_15days = json.load(fp)\n",
    "\n",
    "env_15days = SEIVHRD_Env(params = params, **kwargs_15days)\n",
    "\n",
    "algo_name = \"PPO\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"15daysTest\")\n",
    "models_dir = os.path.join(models_dir,\"15days_rest\")\n",
    "model = PPO.load(models_dir)                        # Charger l'agent RL\n",
    "num_episodes = 100                                  # Nombre d'épisodes simulés\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_3\")\n",
    "simulate_episodes(env_15days, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61717601",
   "metadata": {},
   "source": [
    "## Cas de test 4 : Variation des tailles de populations\n",
    "Le but de ce test est d'évaluer l'agent dans des environments aux tailles de population différentes et savoir s'il est capable d'équilibrer la situation \n",
    "### 1 - Province"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06319dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Tester la stratégie pour la population d une province #############\n",
    "with open('./config/params.json', 'r') as ftp:\n",
    "  params_province = json.load(ftp)\n",
    "with open('./config/env-setup-province.json', 'r') as ftk:\n",
    "  kwargs_province = json.load(ftk)\n",
    "\n",
    "env_province = SEIVHRD_Env(params = params_province, **kwargs_province)\n",
    "algo_name = \"PPO\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"ProvinceTest\")\n",
    "model = PPO.load(os.path.join(models_dir,\"province\"))      # Charger l'agent RL\n",
    "\n",
    "\n",
    "### Restriction-free env\n",
    "action = 0                               # 0 : Pas de restriction      \n",
    "# lancer la simulation\n",
    "run_data = train_standard(env_province,         # Environnement\n",
    "                          T_max=360,       # Nombre de jours dans la simulation\n",
    "                          mode=\"Test\",     # mode de simulation\n",
    "                          selected_action=action)\n",
    "# Visualisation + Enregistrer les images\n",
    "plot_model(env_province, run_data, action=action, main_dir=\"./outputs/figures/Test_Case_4/pop_size/province\")   \n",
    "\n",
    "\n",
    "### Simulation\n",
    "num_episodes = 500                 # Nombre d'épisodes simulés\n",
    "\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_4\")\n",
    "results_dir = os.path.join(results_dir, \"pop_size\")\n",
    "results_dir = os.path.join(results_dir, \"province\")\n",
    "simulate_episodes(env_province, model, num_episodes, results_dir, algo_name)\n",
    "\n",
    "# visualiser un exemple des stratégies\n",
    "num_episodes = 1                                # Nombre d'épisodes simulés\n",
    "simulate_episodes(env_province, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e22d6f",
   "metadata": {},
   "source": [
    "### 2 - Pays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb089543",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Tester la stratégie pour la population d un pays #############\n",
    "with open('./config/params.json', 'r') as ftp:\n",
    "  params_pays = json.load(ftp)\n",
    "with open('./config/env-setup-pays.json', 'r') as ftk:\n",
    "  kwargs_pays = json.load(ftk)\n",
    "\n",
    "env_pays = SEIVHRD_Env(params = params_pays, **kwargs_pays)\n",
    "algo_name = \"PPO\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"PaysTest\")\n",
    "model = PPO.load(os.path.join(models_dir,\"pays\"))      # Charger l'agent RL\n",
    "\n",
    "\n",
    "### Restriction-free env\n",
    "action = 0                               # 0 : Pas de restriction      \n",
    "# lancer la simulation\n",
    "run_data = train_standard(env_pays,         # Environnement\n",
    "                          T_max=360,       # Nombre de jours dans la simulation\n",
    "                          mode=\"Test\",     # mode de simulation\n",
    "                          selected_action=action)\n",
    "# Visualisation + Enregistrer les images\n",
    "plot_model(env_pays, run_data, action=action, main_dir=\"./outputs/figures/Test_Case_4/pop_size/pays\")   \n",
    "\n",
    "\n",
    "### Simulation\n",
    "num_episodes = 500                 # Nombre d'épisodes simulés\n",
    "\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_4\")\n",
    "results_dir = os.path.join(results_dir, \"pop_size\")\n",
    "results_dir = os.path.join(results_dir, \"pays\")\n",
    "simulate_episodes(env_pays, model, num_episodes, results_dir, algo_name)\n",
    "\n",
    "# visualiser un exemple des stratégies\n",
    "num_episodes = 1                                # Nombre d'épisodes simulés\n",
    "simulate_episodes(env_pays, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85238ada",
   "metadata": {},
   "source": [
    "## Cas de test 4 : Régimes inspirés de populations réelles\n",
    "Le but de ce test est d'évaluer l'agent dans des conditions réelles et savoir s'il est capable d'équilibrer la situation \n",
    "### 1 - Tokyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1f694c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "############# Tester la stratégie pour la population de Tokyo #############\n",
    "with open('./config/params-tokyo.json', 'r') as ftp:\n",
    "  params_tokyo = json.load(ftp)\n",
    "with open('./config/env-setup-tokyo.json', 'r') as ftk:\n",
    "  kwargs_tokyo = json.load(ftk)\n",
    "\n",
    "env_tokyo = SEIVHRD_Env(params = params_tokyo, **kwargs_tokyo)\n",
    "algo_name = \"PPO\"\n",
    "region = \"tokyo\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"TokyoTest\")\n",
    "models_dir = os.path.join(models_dir,region)\n",
    "model = PPO.load(models_dir)      # Charger l'agent RL\n",
    "\n",
    "\n",
    "### Restriction-free env\n",
    "action = 0                               # 0 : Pas de restriction      \n",
    "# lancer la simulation\n",
    "run_data = train_standard(env_tokyo,         # Environnement\n",
    "                          T_max=360,       # Nombre de jours dans la simulation\n",
    "                          mode=\"Test\",     # mode de simulation\n",
    "                          selected_action=action)\n",
    "# Visualisation + Enregistrer les images\n",
    "plot_model(env_tokyo, run_data, action=action, main_dir=\"./outputs/figures/Test_Case_4/tokyo/no_restr\")   \n",
    "\n",
    "\n",
    "### Simulation\n",
    "num_episodes = 500                 # Nombre d'épisodes simulés\n",
    "\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_4\")\n",
    "results_dir = os.path.join(results_dir, region)\n",
    "simulate_episodes(env_tokyo, model, num_episodes, results_dir, algo_name)\n",
    "\n",
    "# visualiser un exemple des stratégies\n",
    "num_episodes = 1                                # Nombre d'épisodes simulés\n",
    "simulate_episodes(env_tokyo, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aeae3f",
   "metadata": {},
   "source": [
    "### Ile-de-France"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfcb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Tester la stratégie pour la population de Tokyo #############\n",
    "with open('config/params-ilesdefrance.json', 'r') as ftp:\n",
    "  params_idf = json.load(ftp)\n",
    "with open('config/env-setup-ilesdefrance.json', 'r') as ftk:\n",
    "  kwargs_idf = json.load(ftk)\n",
    "\n",
    "env_idf = SEIVHRD_Env(params = params_idf, **kwargs_idf)\n",
    "algo_name = \"PPO\"\n",
    "region = \"iledefrance\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"IlesdeFranceTest\")\n",
    "models_dir = os.path.join(models_dir,region)\n",
    "model = PPO.load(models_dir)      # Charger l'agent RL\n",
    "\n",
    "### Restriction-free env\n",
    "action = 0                               # 0 : Pas de restriction      \n",
    "# lancer la simulation\n",
    "run_data = train_standard(env_idf,         # Environnement\n",
    "                          T_max=360,       # Nombre de jours dans la simulation\n",
    "                          mode=\"Test\",     # mode de simulation\n",
    "                          selected_action=action)\n",
    "# Visualisation + Enregistrer les images\n",
    "plot_model(env_idf, run_data, action=action, main_dir=\"./outputs/figures/Test_Case_4/iledefrance/no_restr\")   \n",
    "\n",
    "\n",
    "### Simulation\n",
    "num_episodes = 500                 # Nombre d'épisodes simulés\n",
    "\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_4\")\n",
    "results_dir = os.path.join(results_dir, region)\n",
    "simulate_episodes(env_idf, model, num_episodes, results_dir, algo_name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# visualiser un exemple des stratégies\n",
    "num_episodes = 1                                # Nombre d'épisodes simulés\n",
    "simulate_episodes(env_idf, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a47a98f",
   "metadata": {},
   "source": [
    "## Cas de test 5: Tester avec des paramètres personnalisés\n",
    "Le but d'évaluer de l'agent PPO déjà entrainé avec un environnement à des paramètres personnalisables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f76867",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Tester la stratégie pour le régime de vaccination précisé en utilisant l'agent PPO#############\n",
    "params_vacc_pers = {\n",
    "    'gamma' : [7, \n",
    "               10, \n",
    "               16],   \n",
    "    'omega' :  0.01,  #taux de vaccination \n",
    "    'rho'   :  0.08,   #taux d'inefficacité du vaccin\n",
    "    'delta' :  5.1, \n",
    "    'theta' :  5.9,\n",
    "    'mu'    : [10, \n",
    "               14],\n",
    "    'sigma' :  180,\n",
    "    'probas': [0.8,   \n",
    "               0.3,   \n",
    "               0.02,   \n",
    "               0.0727] }\n",
    "\n",
    "env_vacc_pers = SEIVHRD_Env(params = params_vacc_pers, **kwargs)\n",
    "\n",
    "models_dir = f\"./outputs/Model/Default\"\n",
    "model_ppo = PPO.load(f\"{models_dir}/PPO\")    # Charger l'agent RL\n",
    "\n",
    "#num_episodes = 100                                    # Nombre d'épisodes simulés\n",
    "#simulate_episodes(env_vacc_pers, model_ppo, num_episodes, algo_name = models_dir)\n",
    "\n",
    "# visualiser un exemple des stratégies\n",
    "num_episodes = 1                                    # Nombre d'épisodes simulés\n",
    "simulate_episodes(env_vacc_pers, model_ppo, num_episodes, algo_name = models_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6172782e",
   "metadata": {},
   "source": [
    "## Cas de test 5 : Resistance de la population\n",
    "Le but de ce test est d'évaluer l'agent avec différentes sortes de population et savoir s'il est capable d'équilibrer la situation \n",
    "### 1 - Population résistante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244e7833",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Tester la stratégie pour la population d un pays #############\n",
    "with open('./config/params-resistante.json', 'r') as ftp:\n",
    "  params = json.load(ftp)\n",
    "with open('./config/env-setup-ville.json', 'r') as ftk:\n",
    "  kwargs = json.load(ftk)\n",
    "\n",
    "env = SEIVHRD_Env(params = params, **kwargs)\n",
    "algo_name = \"PPO\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"ResistanteTest\")\n",
    "model = PPO.load(os.path.join(models_dir, algo_name))      # Charger l'agent RL\n",
    "\n",
    "\n",
    "### Restriction-free env\n",
    "action = 0                               # 0 : Pas de restriction      \n",
    "# lancer la simulation\n",
    "run_data = train_standard(env,         # Environnement\n",
    "                          T_max=360,       # Nombre de jours dans la simulation\n",
    "                          mode=\"Test\",     # mode de simulation\n",
    "                          selected_action=action)\n",
    "# Visualisation + Enregistrer les images\n",
    "plot_model(env, run_data, action=action, main_dir=\"./outputs/figures/Test_Case_5/resistance/resistant\")   \n",
    "\n",
    "\n",
    "### Simulation\n",
    "num_episodes = 500                 # Nombre d'épisodes simulés\n",
    "\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_5\")\n",
    "results_dir = os.path.join(results_dir, \"resistance\")\n",
    "results_dir = os.path.join(results_dir, \"resistant\")\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)\n",
    "\n",
    "# visualiser un exemple des stratégies\n",
    "num_episodes = 1                                # Nombre d'épisodes simulés\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a455bb9c",
   "metadata": {},
   "source": [
    "### 2 - Population fragile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa01a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Tester la stratégie pour la population d un pays #############\n",
    "with open('./config/params-fragile.json', 'r') as ftp:\n",
    "  params = json.load(ftp)\n",
    "with open('./config/env-setup-ville.json', 'r') as ftk:\n",
    "  kwargs = json.load(ftk)\n",
    "\n",
    "env = SEIVHRD_Env(params = params, **kwargs)\n",
    "algo_name = \"PPO\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"ResistanteTest\")\n",
    "model = PPO.load(os.path.join(models_dir, algo_name))      # Charger l'agent RL\n",
    "\n",
    "\n",
    "### Restriction-free env\n",
    "action = 0                               # 0 : Pas de restriction      \n",
    "# lancer la simulation\n",
    "run_data = train_standard(env,         # Environnement\n",
    "                          T_max=360,       # Nombre de jours dans la simulation\n",
    "                          mode=\"Test\",     # mode de simulation\n",
    "                          selected_action=action)\n",
    "# Visualisation + Enregistrer les images\n",
    "plot_model(env, run_data, action=action, main_dir=\"./outputs/figures/Test_Case_5/resistance/fragile\")   \n",
    "\n",
    "\n",
    "### Simulation\n",
    "num_episodes = 500                 # Nombre d'épisodes simulés\n",
    "\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_5\")\n",
    "results_dir = os.path.join(results_dir, \"resistance\")\n",
    "results_dir = os.path.join(results_dir, \"fragile\")\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)\n",
    "\n",
    "# visualiser un exemple des stratégies\n",
    "num_episodes = 1                                # Nombre d'épisodes simulés\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7dfc9d0",
   "metadata": {},
   "source": [
    "### 3 - Population plus résistante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada4b6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Tester la stratégie pour la population d un pays #############\n",
    "with open('./config/params-resistante.json', 'r') as ftp:\n",
    "  params = json.load(ftp)\n",
    "with open('./config/env-setup-ville.json', 'r') as ftk:\n",
    "  kwargs = json.load(ftk)\n",
    "\n",
    "env = SEIVHRD_Env(params = params, **kwargs)\n",
    "algo_name = \"PPO\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"Default\")\n",
    "model = PPO.load(os.path.join(models_dir, algo_name))      # Charger l'agent RL\n",
    "\n",
    "\n",
    "### Restriction-free env\n",
    "action = 0                               # 0 : Pas de restriction      \n",
    "# lancer la simulation\n",
    "run_data = train_standard(env,         # Environnement\n",
    "                          T_max=360,       # Nombre de jours dans la simulation\n",
    "                          mode=\"Test\",     # mode de simulation\n",
    "                          selected_action=action)\n",
    "# Visualisation + Enregistrer les images\n",
    "plot_model(env, run_data, action=action, main_dir=\"./outputs/figures/Test_Case_5/resistance/more_resistant\")   \n",
    "\n",
    "\n",
    "### Simulation\n",
    "num_episodes = 500                 # Nombre d'épisodes simulés\n",
    "\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_5\")\n",
    "results_dir = os.path.join(results_dir, \"resistance\")\n",
    "results_dir = os.path.join(results_dir, \"more_resistant\")\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)\n",
    "\n",
    "# visualiser un exemple des stratégies\n",
    "num_episodes = 1                                # Nombre d'épisodes simulés\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0aa75d",
   "metadata": {},
   "source": [
    "### 4 - Population plus fragile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b3ea77",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Tester la stratégie pour la population d un pays #############\n",
    "with open('./config/params-fragile.json', 'r') as ftp:\n",
    "  params = json.load(ftp)\n",
    "with open('./config/env-setup-ville.json', 'r') as ftk:\n",
    "  kwargs = json.load(ftk)\n",
    "\n",
    "env = SEIVHRD_Env(params = params, **kwargs)\n",
    "algo_name = \"PPO\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"Default\")\n",
    "model = PPO.load(os.path.join(models_dir, algo_name))      # Charger l'agent RL\n",
    "\n",
    "\n",
    "### Restriction-free env\n",
    "action = 0                               # 0 : Pas de restriction      \n",
    "# lancer la simulation\n",
    "run_data = train_standard(env,         # Environnement\n",
    "                          T_max=360,       # Nombre de jours dans la simulation\n",
    "                          mode=\"Test\",     # mode de simulation\n",
    "                          selected_action=action)\n",
    "# Visualisation + Enregistrer les images\n",
    "plot_model(env, run_data, action=action, main_dir=\"./outputs/figures/Test_Case_5/resistance/more_fragile\")   \n",
    "\n",
    "\n",
    "### Simulation\n",
    "num_episodes = 500                 # Nombre d'épisodes simulés\n",
    "\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_5\")\n",
    "results_dir = os.path.join(results_dir, \"resistance\")\n",
    "results_dir = os.path.join(results_dir, \"more_fragile\")\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)\n",
    "\n",
    "# visualiser un exemple des stratégies\n",
    "num_episodes = 1                                # Nombre d'épisodes simulés\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e0db5",
   "metadata": {},
   "source": [
    "## Cas de test 5 :  Rythme de vaccination\n",
    "Le but de ce test est d'évaluer l'agent avec différentes régimes de vaccination et savoir s'il est capable d'équilibrer la situation \n",
    "### 1 - Vaccination précoce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84345514",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Tester la stratégie pour la population d un pays #############\n",
    "with open('./config/params-vaccination.json', 'r') as ftp:\n",
    "  params = json.load(ftp)\n",
    "  \n",
    "with open('./config/env-setup-ville.json', 'r') as ftk:\n",
    "  kwargs = json.load(ftk)\n",
    "\n",
    "env = SEIVHRD_Env(params = params, **kwargs)\n",
    "algo_name = \"PPO\"\n",
    "models_dir = os.path.join(\"./outputs/Model\",\"VaccinationTest\")\n",
    "model = PPO.load(os.path.join(models_dir, 'precoce'))      # Charger l'agent RL\n",
    "\n",
    "\n",
    "### Restriction-free env\n",
    "action = 0                               # 0 : Pas de restriction      \n",
    "# lancer la simulation\n",
    "run_data = train_standard(env,         # Environnement\n",
    "                          T_max=360,       # Nombre de jours dans la simulation\n",
    "                          mode=\"Test\",     # mode de simulation\n",
    "                          selected_action=action)\n",
    "# Visualisation + Enregistrer les images\n",
    "plot_model(env, run_data, action=action, main_dir=\"./outputs/figures/Test_Case_5/vaccination/early\")   \n",
    "\n",
    "\n",
    "### Simulation\n",
    "num_episodes = 500                 # Nombre d'épisodes simulés\n",
    "\n",
    "results_dir = os.path.join(f\"./outputs/figures\", \"Test_Case_5\")\n",
    "results_dir = os.path.join(results_dir, \"vaccination\")\n",
    "results_dir = os.path.join(results_dir, \"early\")\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)\n",
    "\n",
    "# visualiser un exemple des stratégies\n",
    "num_episodes = 1                                # Nombre d'épisodes simulés\n",
    "simulate_episodes(env, model, num_episodes, results_dir, algo_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ac7000",
   "metadata": {},
   "source": [
    "## - Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb58f41",
   "metadata": {},
   "source": [
    "### 1 - PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc84997",
   "metadata": {},
   "outputs": [],
   "source": [
    "################    MAIN - PPO   ###################\n",
    "env.reset()\n",
    "models_dir = f\"./outputs/Model/training/PPO\"\n",
    "log_dir = \"./outputs/logs/training/PPO\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "model_ppo = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)\n",
    "TIMESTEPS = 10000\n",
    "for i in range(0,50):\n",
    "    model_ppo.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"{algo_name}_{7}/{7.75}_{1}\")\n",
    "    model_ppo.save(f\"{models_dir}/{TIMESTEPS*i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481d8167",
   "metadata": {},
   "outputs": [],
   "source": [
    "################    MAIN - DQN   ###################\n",
    "algo_name=\"DQN\"\n",
    "env.reset()\n",
    "models_dir = f\"./outputs/Model/training/{algo_name}\"\n",
    "log_dir = f\"./outputs/logs/training/{algo_name}\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "model_ppo = DQN(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)\n",
    "TIMESTEPS = 10000\n",
    "for i in range(0,50):\n",
    "    model_ppo.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"{algo_name}_{7}/{7.75}_{1}\")\n",
    "    model_ppo.save(f\"{models_dir}/{TIMESTEPS*i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ec8ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "################    MAIN - DDQN   ###################\n",
    "algo_name=\"DDQN\"\n",
    "env.reset()\n",
    "models_dir = f\"./outputs/Model/training/{algo_name}\"\n",
    "log_dir = f\"./outputs/logs/training/{algo_name}\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "model_ppo = DQN(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)\n",
    "TIMESTEPS = 10000\n",
    "for i in range(0,50):\n",
    "    model_ppo.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"{algo_name}_{7}/{7.75}_{1}\")\n",
    "    model_ppo.save(f\"{models_dir}/{TIMESTEPS*i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403a2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################    MAIN - A2C   ###################\n",
    "algo_name=\"A2C\"\n",
    "env.reset()\n",
    "models_dir = f\"./outputs/Model/training/{algo_name}\"\n",
    "log_dir = f\"./outputs/logs/training/{algo_name}\"\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "model_ppo = A2C(\"MlpPolicy\", env, verbose=1, tensorboard_log=log_dir)\n",
    "TIMESTEPS = 10000\n",
    "for i in range(0,50):\n",
    "    model_ppo.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"{algo_name}_{7}/{7.75}_{1}\")\n",
    "    model_ppo.save(f\"{models_dir}/{TIMESTEPS*i}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "4d2f2a953d53bb594cffb805c0c1aba68858eafe14d2662182aaf533ab68d96d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
